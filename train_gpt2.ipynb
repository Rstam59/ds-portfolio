{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFAhlB/tSyGiSGLnaQmPZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96aa4e97e1ef4e3f88ebe747631a4d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58abc960830e45bbb805c8e6b7b32c11",
              "IPY_MODEL_497ffa34d1b343ffa3ae488c13b7b7ff",
              "IPY_MODEL_b1f6a33cbad7481eaab23f8f6ea55e8e"
            ],
            "layout": "IPY_MODEL_b28bd9f8906d470d8f1b7a07d617eaa2"
          }
        },
        "58abc960830e45bbb805c8e6b7b32c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559d39eba0d84ff4b6168504388ef9ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d0513299cac3489496d1412e492b7f09",
            "value": "config.json: 100%"
          }
        },
        "497ffa34d1b343ffa3ae488c13b7b7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12109781bdf44b8e85f3aa18007c96c9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b92094decbd40d085e1150af3a2207e",
            "value": 665
          }
        },
        "b1f6a33cbad7481eaab23f8f6ea55e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51bc55cae0a4906b4f4e387ca785484",
            "placeholder": "​",
            "style": "IPY_MODEL_c79d46909c564e6fbb2171c037752ab1",
            "value": " 665/665 [00:00&lt;00:00, 48.7kB/s]"
          }
        },
        "b28bd9f8906d470d8f1b7a07d617eaa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559d39eba0d84ff4b6168504388ef9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0513299cac3489496d1412e492b7f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12109781bdf44b8e85f3aa18007c96c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b92094decbd40d085e1150af3a2207e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c51bc55cae0a4906b4f4e387ca785484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79d46909c564e6fbb2171c037752ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d49057e4f24c4ca6c050b901ebb1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25af758fbb01469486c0a7ebea72710d",
              "IPY_MODEL_e426a0ab0c7545bf9bde728ef1c9274f",
              "IPY_MODEL_c21d5df04af0483398e4c942ea1ef89a"
            ],
            "layout": "IPY_MODEL_5993e0526f5e4696a5d15093264c4c95"
          }
        },
        "25af758fbb01469486c0a7ebea72710d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fb68647a214a99a38b6136cc261648",
            "placeholder": "​",
            "style": "IPY_MODEL_98f31f3713d94edd81d08c22c68f4536",
            "value": "model.safetensors: 100%"
          }
        },
        "e426a0ab0c7545bf9bde728ef1c9274f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b57f8a8f0149fc9568db505b587a85",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7d6b165923c4d7499325f4aa2d544a6",
            "value": 548105171
          }
        },
        "c21d5df04af0483398e4c942ea1ef89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8fd2b6193e4d359fce9580ddd9bfa9",
            "placeholder": "​",
            "style": "IPY_MODEL_90c92577496641368f5ac013e2b1b6dd",
            "value": " 548M/548M [00:07&lt;00:00, 76.8MB/s]"
          }
        },
        "5993e0526f5e4696a5d15093264c4c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fb68647a214a99a38b6136cc261648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f31f3713d94edd81d08c22c68f4536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02b57f8a8f0149fc9568db505b587a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d6b165923c4d7499325f4aa2d544a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d8fd2b6193e4d359fce9580ddd9bfa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c92577496641368f5ac013e2b1b6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5aba8a285d74ecaa03397aacfee0cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04bfec336839421bac3f26326d26568b",
              "IPY_MODEL_efdd65e2f175430a8fb5051a75a763c3",
              "IPY_MODEL_b6c2ff5a85cb43d8a05a5699903eb6e1"
            ],
            "layout": "IPY_MODEL_e8315c9e2f6f42e083eb0d8f528b7bea"
          }
        },
        "04bfec336839421bac3f26326d26568b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e9ee9fb15346ad9a2acbc6f91bf249",
            "placeholder": "​",
            "style": "IPY_MODEL_dee084807f8a4c4d82c9aa1f265cf38b",
            "value": "generation_config.json: 100%"
          }
        },
        "efdd65e2f175430a8fb5051a75a763c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6328a7d767214236920c241e6d41b603",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f6cd91019904cfc84d60f5cfed22ae5",
            "value": 124
          }
        },
        "b6c2ff5a85cb43d8a05a5699903eb6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f01108857c3e4fd594eee40efb1b2787",
            "placeholder": "​",
            "style": "IPY_MODEL_a0bba83009fa48c9861c136cb7c23ce8",
            "value": " 124/124 [00:00&lt;00:00, 6.74kB/s]"
          }
        },
        "e8315c9e2f6f42e083eb0d8f528b7bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e9ee9fb15346ad9a2acbc6f91bf249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee084807f8a4c4d82c9aa1f265cf38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6328a7d767214236920c241e6d41b603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6cd91019904cfc84d60f5cfed22ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f01108857c3e4fd594eee40efb1b2787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bba83009fa48c9861c136cb7c23ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rstam59/ds-portfolio/blob/main/train_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62hJinCa6mHA"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class CasualSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        #output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "        #Regularization\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        #bad naming\n",
        "        self.register_buffer('bias', torch.tril(torch.ones(config.block_size, config.block_size)).\n",
        "                             view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        #calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        #compute attention scores\n",
        "        # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        # att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        # att = F.softmax(att, dim=-1)\n",
        "        # y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.c_proj(y)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "QTsRdT2xF0Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TanhGelu(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return 0.5 * (1 + torch.tanh(math.sqrt(2 / math.pi) * (input + 0.044715 * torch.pow(input, 3))))\n"
      ],
      "metadata": {
        "id": "qEMxJjmSTx4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.gelu = nn.GELU(approximate= 'tanh')\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5keC897nC4ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CasualSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "FrADitg5CC9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50257\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768"
      ],
      "metadata": {
        "id": "LxiRmSuy6voh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            h = nn.ModuleList(Block(config) for _ in range(config.n_layer)),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias = False)\n",
        "\n",
        "\n",
        "        #weight sharing scheme\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            std = 0.02\n",
        "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
        "                std = (2 * self.config.n_layer) ** -0.5\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = tok_emb + pos_emb\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(self.lm_head(x.view(-1, x.size(-1))), targets.view(-1))\n",
        "        logits = self.lm_head(x)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        '''Loads pretrained GPT-2 model weights from huggingface'''\n",
        "        assert model_type in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print('Loading weights from huggingface...')\n",
        "\n",
        "        config_args = {\n",
        "            \"gpt2\":  dict(n_layer=12, n_head=12, n_embd=768), #124M params\n",
        "            \"gpt2-medium\": dict(n_layer=24, n_head=16, n_embd=1024), #355M params\n",
        "            \"gpt2-large\": dict(n_layer=36, n_head=20, n_embd=1280), #774M params\n",
        "            \"gpt2-xl\": dict(n_layer=48, n_head=25, n_embd=1600), #1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257\n",
        "        config_args['block_size'] = 1024\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')]\n",
        "\n",
        "        #init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        #copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')]\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        assert len(sd_keys) == len(sd_keys_hf), f'mismatched number of keys: {len(sd_keys)} vs {len(sd_keys_hf)}'\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape, f'mismatched shape for {k}: {sd[k].shape} vs {sd_hf[k].shape}'\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape, f'mismatched shape for {k}: {sd[k].shape} vs {sd_hf[k].shape}'\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "model = GPT.from_pretrained('gpt2')\n",
        "print(model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Ra0PfSI69le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634,
          "referenced_widgets": [
            "96aa4e97e1ef4e3f88ebe747631a4d00",
            "58abc960830e45bbb805c8e6b7b32c11",
            "497ffa34d1b343ffa3ae488c13b7b7ff",
            "b1f6a33cbad7481eaab23f8f6ea55e8e",
            "b28bd9f8906d470d8f1b7a07d617eaa2",
            "559d39eba0d84ff4b6168504388ef9ec",
            "d0513299cac3489496d1412e492b7f09",
            "12109781bdf44b8e85f3aa18007c96c9",
            "7b92094decbd40d085e1150af3a2207e",
            "c51bc55cae0a4906b4f4e387ca785484",
            "c79d46909c564e6fbb2171c037752ab1",
            "33d49057e4f24c4ca6c050b901ebb1df",
            "25af758fbb01469486c0a7ebea72710d",
            "e426a0ab0c7545bf9bde728ef1c9274f",
            "c21d5df04af0483398e4c942ea1ef89a",
            "5993e0526f5e4696a5d15093264c4c95",
            "89fb68647a214a99a38b6136cc261648",
            "98f31f3713d94edd81d08c22c68f4536",
            "02b57f8a8f0149fc9568db505b587a85",
            "d7d6b165923c4d7499325f4aa2d544a6",
            "7d8fd2b6193e4d359fce9580ddd9bfa9",
            "90c92577496641368f5ac013e2b1b6dd",
            "e5aba8a285d74ecaa03397aacfee0cf2",
            "04bfec336839421bac3f26326d26568b",
            "efdd65e2f175430a8fb5051a75a763c3",
            "b6c2ff5a85cb43d8a05a5699903eb6e1",
            "e8315c9e2f6f42e083eb0d8f528b7bea",
            "10e9ee9fb15346ad9a2acbc6f91bf249",
            "dee084807f8a4c4d82c9aa1f265cf38b",
            "6328a7d767214236920c241e6d41b603",
            "7f6cd91019904cfc84d60f5cfed22ae5",
            "f01108857c3e4fd594eee40efb1b2787",
            "a0bba83009fa48c9861c136cb7c23ce8"
          ]
        },
        "outputId": "234c41bd-eb14-464b-b37c-0a14f9402022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from huggingface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96aa4e97e1ef4e3f88ebe747631a4d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33d49057e4f24c4ca6c050b901ebb1df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5aba8a285d74ecaa03397aacfee0cf2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT(\n",
            "  (transformer): ModuleDict(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): CasualSelfAttention(\n",
            "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (gelu): GELU(approximate='tanh')\n",
            "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "print(device)\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41MoFBEv1ZYx",
        "outputId": "7c33296c-46f7-4904-eb7c-9a01f3f0863e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_return_sequences = 5\n",
        "max_length = 30\n",
        "\n",
        "# model = GPT.from_pretrained('gpt2')\n",
        "model = GPT(GPTConfig(vocab_size = 50304))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqgoRea8vU9L",
        "outputId": "312f08af-2de9-43e2-d87c-cc033f51e405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50304, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CasualSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='tanh')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69BzCJYdv-Ey",
        "outputId": "7b462159-66e2-4e4a-ecbe-cff8babd8d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tiktoken\n",
        "# enc = tiktoken.get_encoding(\"gpt2\")\n",
        "# tokens = enc.encode(\"Hello, I'm a language model\")\n",
        "# tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "# tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
        "# x = tokens.to(device)\n",
        "\n",
        "# torch.manual_seed(42)\n",
        "# torch.cuda.manual_seed(42)\n",
        "# while x.size(1) < max_length:\n",
        "#     with torch.no_grad():\n",
        "#         logits = model(x)\n",
        "#         logits = logits[:, -1, :]\n",
        "#         probs = F.softmax(logits, dim=-1)\n",
        "#         # next_token = torch.multinomial(probs, num_samples=1)\n",
        "#         # tokens = torch.cat([tokens, next_token], dim=1)\n",
        "#         topk_probs, topk_indices = torch.topk(probs, k=50, dim=-1)\n",
        "#         ix = torch.multinomial(topk_probs, 1)\n",
        "#         xcol = torch.gather(topk_indices, -1, ix)\n",
        "#         x = torch.cat([x, xcol], dim=1)"
      ],
      "metadata": {
        "id": "NzX6Fx8WNZX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(num_return_sequences):\n",
        "#     tokens = x[i, :max_length].tolist()\n",
        "#     decoded = enc.decode(tokens)\n",
        "#     print('>', decoded)"
      ],
      "metadata": {
        "id": "RbGG-Q9fv9BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://raw.githubusercontent.com/karpathy/build-nanogpt/refs/heads/master/input.txt"
      ],
      "metadata": {
        "id": "udNjL-QA0eYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab4da3a-543b-4e01-ff42-45ed460e33b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-04 13:31:40--  https://raw.githubusercontent.com/karpathy/build-nanogpt/refs/heads/master/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-04 13:31:41 (27.6 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "np.random.randint(0, 60, size = (6, 10))"
      ],
      "metadata": {
        "id": "-E8IQ46U6QTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c66befe-3786-4615-941d-5b46711875cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50, 52, 16, 49, 30, 42, 39, 11, 28, 11],\n",
              "       [26, 46, 17,  1, 23, 20, 29, 45,  8, 30],\n",
              "       [ 6, 52,  5, 11, 14, 58, 19,  8, 53, 42],\n",
              "       [54, 55, 38, 33, 47, 58, 48, 23,  0,  2],\n",
              "       [46, 52,  3,  0, 55, 58, 12, 48, 31, 13],\n",
              "       [18, 50, 37, 46,  9, 47, 21, 26,  9, 37]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "with open('input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "text = text[:1000]\n",
        "tokens = enc.encode(text)\n",
        "B, T = 4, 32\n",
        "buf = torch.tensor(tokens[:B*T + 1])\n",
        "buf = buf.to(device)\n",
        "x = buf[:-1].view(B, T)\n",
        "y = buf[1:].view(B, T)\n",
        "model = GPT(GPTConfig())\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas = (0.9, 0.95), eps = 1e-8)\n",
        "for i in range(50):\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    logits, loss = model(x, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"step {i}, loss: {loss.item()}\")\n",
        "\n",
        "# import sys; sys.exit(0)"
      ],
      "metadata": {
        "id": "pv5BieaMh5Kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649990d1-59a4-4fd7-fc63-7cb6923abdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, loss: 10.8391695022583\n",
            "step 1, loss: 8.467406272888184\n",
            "step 2, loss: 7.6278791427612305\n",
            "step 3, loss: 7.323618412017822\n",
            "step 4, loss: 6.522852897644043\n",
            "step 5, loss: 6.038125991821289\n",
            "step 6, loss: 5.57582950592041\n",
            "step 7, loss: 5.062967300415039\n",
            "step 8, loss: 4.563469409942627\n",
            "step 9, loss: 3.976896286010742\n",
            "step 10, loss: 3.226181983947754\n",
            "step 11, loss: 3.2245426177978516\n",
            "step 12, loss: 2.614743232727051\n",
            "step 13, loss: 2.4133968353271484\n",
            "step 14, loss: 1.928017497062683\n",
            "step 15, loss: 1.628973126411438\n",
            "step 16, loss: 1.1532443761825562\n",
            "step 17, loss: 0.9028757214546204\n",
            "step 18, loss: 0.6945186853408813\n",
            "step 19, loss: 0.4917982518672943\n",
            "step 20, loss: 0.3521387577056885\n",
            "step 21, loss: 0.24547846615314484\n",
            "step 22, loss: 0.16462981700897217\n",
            "step 23, loss: 0.11487781256437302\n",
            "step 24, loss: 0.0849955603480339\n",
            "step 25, loss: 0.06487804651260376\n",
            "step 26, loss: 0.050571419298648834\n",
            "step 27, loss: 0.040224138647317886\n",
            "step 28, loss: 0.03273648023605347\n",
            "step 29, loss: 0.02722962014377117\n",
            "step 30, loss: 0.023079179227352142\n",
            "step 31, loss: 0.01988239586353302\n",
            "step 32, loss: 0.017362957820296288\n",
            "step 33, loss: 0.015327406115829945\n",
            "step 34, loss: 0.013644516468048096\n",
            "step 35, loss: 0.012227559462189674\n",
            "step 36, loss: 0.011018472723662853\n",
            "step 37, loss: 0.009976359084248543\n",
            "step 38, loss: 0.009071041829884052\n",
            "step 39, loss: 0.008279766887426376\n",
            "step 40, loss: 0.0075846705585718155\n",
            "step 41, loss: 0.006971715949475765\n",
            "step 42, loss: 0.006429578177630901\n",
            "step 43, loss: 0.005948858801275492\n",
            "step 44, loss: 0.005521534476429224\n",
            "step 45, loss: 0.005140863358974457\n",
            "step 46, loss: 0.004800891969352961\n",
            "step 47, loss: 0.004496620502322912\n",
            "step 48, loss: 0.004223536234349012\n",
            "step 49, loss: 0.003977866377681494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-np.log(1 / 50257)"
      ],
      "metadata": {
        "id": "ujCAfmLt7riD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b70554f-9cc1-4199-ddf1-8605d9c746cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.82490511970208"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoaderLite:\n",
        "    def __init__(self, B, T):\n",
        "        self.B = B\n",
        "        self.T = T\n",
        "\n",
        "\n",
        "        with open ('input.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "        enc = tiktoken.get_encoding('gpt2')\n",
        "        tokens = enc.encode(text)\n",
        "        self.tokens = torch.tensor(tokens)\n",
        "        print(f\"loaded {len(self.tokens)} tokens\")\n",
        "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
        "\n",
        "\n",
        "        self.current_position = 0\n",
        "\n",
        "\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "        buf = self.tokens[self.current_position:self.current_position + B*T + 1]\n",
        "        x = buf[:-1].view(B, T)\n",
        "        y = buf[1:].view(B, T)\n",
        "        self.current_position += B*T + 1\n",
        "\n",
        "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
        "            self.current_position = 0\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "_LP2vrEni6ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoaderLite(4, 32)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "for i in range(50):\n",
        "    x, y = train_loader.next_batch()\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    logits, loss = model(x, y)\n",
        "    # import code; code.interact(local=locals())\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "    print(f\"step {i}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "w0maiQXO3gdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f397f4d4-5788-4330-d70c-90b1c6b9f7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 2640 batches\n",
            "step 0, loss: 0.0037562581710517406\n",
            "step 1, loss: 9.976945877075195\n",
            "step 2, loss: 10.49441146850586\n",
            "step 3, loss: 9.231887817382812\n",
            "step 4, loss: 8.05864143371582\n",
            "step 5, loss: 7.871607780456543\n",
            "step 6, loss: 8.50680923461914\n",
            "step 7, loss: 7.795938014984131\n",
            "step 8, loss: 7.358175754547119\n",
            "step 9, loss: 7.397676467895508\n",
            "step 10, loss: 7.770276069641113\n",
            "step 11, loss: 6.63814115524292\n",
            "step 12, loss: 6.903777599334717\n",
            "step 13, loss: 6.934110164642334\n",
            "step 14, loss: 7.094895362854004\n",
            "step 15, loss: 7.114306449890137\n",
            "step 16, loss: 7.802863121032715\n",
            "step 17, loss: 8.318770408630371\n",
            "step 18, loss: 6.702744007110596\n",
            "step 19, loss: 7.878968238830566\n",
            "step 20, loss: 7.33986759185791\n",
            "step 21, loss: 7.122585773468018\n",
            "step 22, loss: 6.599552154541016\n",
            "step 23, loss: 6.899408340454102\n",
            "step 24, loss: 6.51102352142334\n",
            "step 25, loss: 6.55588960647583\n",
            "step 26, loss: 6.602773189544678\n",
            "step 27, loss: 7.831883907318115\n",
            "step 28, loss: 6.579095363616943\n",
            "step 29, loss: 6.6640400886535645\n",
            "step 30, loss: 6.847659111022949\n",
            "step 31, loss: 7.395177841186523\n",
            "step 32, loss: 6.441439151763916\n",
            "step 33, loss: 7.631433963775635\n",
            "step 34, loss: 7.930541515350342\n",
            "step 35, loss: 7.947740077972412\n",
            "step 36, loss: 7.394611835479736\n",
            "step 37, loss: 7.933818817138672\n",
            "step 38, loss: 7.135780334472656\n",
            "step 39, loss: 7.0579304695129395\n",
            "step 40, loss: 6.823665142059326\n",
            "step 41, loss: 6.350053787231445\n",
            "step 42, loss: 6.566277027130127\n",
            "step 43, loss: 5.78356409072876\n",
            "step 44, loss: 6.53765344619751\n",
            "step 45, loss: 6.221614837646484\n",
            "step 46, loss: 6.400847434997559\n",
            "step 47, loss: 7.148651599884033\n",
            "step 48, loss: 7.124646186828613\n",
            "step 49, loss: 7.289739608764648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "rLPRjUYM5eVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9eb6164-503b-45eb-b36e-262e0fb9e234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb  4 13:32:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0             81W /   70W |    4394MiB /  15360MiB |     96%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.dtype"
      ],
      "metadata": {
        "id": "8LRS3YwOPY4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c4cb5e-0e6f-4e56-c4f6-edb56910f1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "print(device)\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1337)\n",
        "\n",
        "\n",
        "train_loader = DataLoaderLite(B = 4, T = 1024)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "model = GPT(GPTConfig())\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 10\n",
        "max_steps = 50\n",
        "\n",
        "def get_lr(it):\n",
        "    # 1) Linear warmup for warmup_iters steos\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it + 1) / warmup_steps\n",
        "    # 2) If it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas = (0.9, 0.95), eps = 1e-8)\n",
        "for step in range(20):\n",
        "    t0 = time.time()\n",
        "    x, y = train_loader.next_batch()\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    # with torch.autocast(device_type=device, dtype = torch.bfloat16):\n",
        "    with torch.autocast(device_type=device):\n",
        "        logits, loss = model(x, y)\n",
        "    loss.backward()\n",
        "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    lr = get_lr(step)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    optimizer.step()\n",
        "    torch.cuda.synchronize()\n",
        "    t1 = time.time()\n",
        "    dt = (t1 - t0) * 1000\n",
        "    tokens_per_sec = (train_loader.B * train_loader.T) / (t1 - t0)\n",
        "    print(f\"step {step}, loss: {loss.item()},|lr {lr:.2f} | norm {norm:.4f} |time: {dt:.2f}ms, tok/sec: {tokens_per_sec:.4f}\")\n"
      ],
      "metadata": {
        "id": "uqNrkYUPGcMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f299b69-699d-4789-8021-3af40ed6ca58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "loaded 338025 tokens\n",
            "1 epoch = 82 batches\n",
            "step 0, loss: 10.911243438720703,|lr 0.00 | norm 10.5407 |time: 43778.20ms, tok/sec: 93.5626\n",
            "step 1, loss: 9.986283302307129,|lr 0.00 | norm 5.9940 |time: 307.47ms, tok/sec: 13321.6419\n",
            "step 2, loss: 9.522709846496582,|lr 0.00 | norm 3.4028 |time: 315.95ms, tok/sec: 12964.0898\n",
            "step 3, loss: 9.291451454162598,|lr 0.00 | norm 4.7312 |time: 321.15ms, tok/sec: 12754.0201\n",
            "step 4, loss: 8.905405044555664,|lr 0.00 | norm 3.1478 |time: 310.54ms, tok/sec: 13190.1112\n",
            "step 5, loss: 8.662164688110352,|lr 0.00 | norm 3.2452 |time: 310.72ms, tok/sec: 13182.2169\n",
            "step 6, loss: 8.626821517944336,|lr 0.00 | norm 3.1642 |time: 311.47ms, tok/sec: 13150.3617\n",
            "step 7, loss: 8.504057884216309,|lr 0.00 | norm 3.3615 |time: 309.86ms, tok/sec: 13219.0056\n",
            "step 8, loss: 8.430315017700195,|lr 0.00 | norm 2.4430 |time: 312.12ms, tok/sec: 13123.2697\n",
            "step 9, loss: 8.176719665527344,|lr 0.00 | norm 2.0570 |time: 313.04ms, tok/sec: 13084.4197\n",
            "step 10, loss: 8.124675750732422,|lr 0.00 | norm 1.8395 |time: 310.42ms, tok/sec: 13195.0955\n",
            "step 11, loss: 8.01578140258789,|lr 0.00 | norm 1.9845 |time: 312.27ms, tok/sec: 13116.8872\n",
            "step 12, loss: 7.9866838455200195,|lr 0.00 | norm 2.3955 |time: 305.74ms, tok/sec: 13396.9988\n",
            "step 13, loss: 7.839966773986816,|lr 0.00 | norm 2.0926 |time: 310.09ms, tok/sec: 13209.2687\n",
            "step 14, loss: 7.4853949546813965,|lr 0.00 | norm 2.1046 |time: 313.91ms, tok/sec: 13048.3058\n",
            "step 15, loss: 7.425027847290039,|lr 0.00 | norm 1.5881 |time: 312.03ms, tok/sec: 13127.0400\n",
            "step 16, loss: 7.212098121643066,|lr 0.00 | norm 1.5982 |time: 310.37ms, tok/sec: 13197.1633\n",
            "step 17, loss: 7.039533615112305,|lr 0.00 | norm 1.4291 |time: 305.60ms, tok/sec: 13403.2073\n",
            "step 18, loss: 7.092180252075195,|lr 0.00 | norm 1.3757 |time: 316.50ms, tok/sec: 12941.4918\n",
            "step 19, loss: 7.06967830657959,|lr 0.00 | norm 1.7584 |time: 311.57ms, tok/sec: 13146.4371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QN0GE8UXRNX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-dCLl4yMqb7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}