{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPA0ZSpHjWsFdqoyZTB+30s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rstam59/ds-portfolio/blob/main/Classification_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qr4YKDD5Ty2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmvRmLNlTR3h"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import list_datasets\n",
        "\n",
        "all_dataset = list(list_datasets())  # convert generator to list\n",
        "print(f\"Total number of datasets: {len(all_dataset)}\")\n",
        "print(f\"First 10 datasets: {all_dataset[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "MwziJ9F3Vz_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U fsspec\n"
      ],
      "metadata": {
        "id": "11itE3scWPM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset  # not load_datasets\n",
        "\n",
        "emotions = load_dataset(\"emotion\")\n",
        "print(emotions)\n"
      ],
      "metadata": {
        "id": "Jnxfh8fyTc0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions['train']\n",
        "train_ds"
      ],
      "metadata": {
        "id": "68ScleIMk5b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "3arxca65reeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " train_ds.features"
      ],
      "metadata": {
        "id": "nu73KImjlD2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds['text'][:5]"
      ],
      "metadata": {
        "id": "Uiq1mbA_lD6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_pxPBxHlD85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions['train']\n",
        "train_ds"
      ],
      "metadata": {
        "id": "0bHCgO6yc60L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "dW4AxKSnWksm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "id": "VvIPnBndWqqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.column_names"
      ],
      "metadata": {
        "id": "eaVcDo0yWxhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.features)"
      ],
      "metadata": {
        "id": "WvTnUvuOW-pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds[:5])"
      ],
      "metadata": {
        "id": "8jqA4M-tZNUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds['text'][:5])"
      ],
      "metadata": {
        "id": "xIDdFK3LZaZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What if my dataset is not on the hub"
      ],
      "metadata": {
        "id": "aizemGgdbA53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://huggingface.co/datasets/transformersbook/emotion-train-split/raw/main/train.txt\"\n",
        "!wget {dataset_url}"
      ],
      "metadata": {
        "id": "FbG44cKabMsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 train.txt"
      ],
      "metadata": {
        "id": "juKEpOY5clJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_local = load_dataset('csv', data_files='train.txt', sep = ';', names = ['text', 'label'])"
      ],
      "metadata": {
        "id": "HNYpyNKTiaBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnXHEU4LiZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J81XF6leiZ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_local = load_dataset('csv', data_files = 'train.txt', sep = ';', names = ['text', 'label'])"
      ],
      "metadata": {
        "id": "kG74HslHdFQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simpler\n",
        "dataset_url = \"https://huggingface.co/datasets/transformersbook/emotion-train-split/raw/main/train.txt\"\n",
        "emotions_remote = load_dataset(\"csv\", data_files=dataset_url, sep=\";\",\n",
        "                               names=[\"text\", \"label\"])"
      ],
      "metadata": {
        "id": "w9s84ppKd9eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From datasets to DataFrames"
      ],
      "metadata": {
        "id": "UhGtrLjYeQzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type = 'pandas')\n",
        "\n",
        "df = emotions['train'][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "K2C_ZA_biZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "    return emotions['train'].features['label'].int2str(row)\n",
        "\n",
        "df['label_name'] = df['label'].apply(label_int2str)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "C_RjE1URiY_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['label_name'].value_counts().plot.barh()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rLC_DiAQiY6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Words Per Tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot('Words Per Tweet', by = 'label_name', grid = False, showfliers = False, color = 'black')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cCoeaLGiiYzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "ZzDcR04rxBm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type = 'pandas')\n",
        "df = emotions['train'][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KZIQ4Bq3eWr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "    return emotions['train'].features['label'].int2str(row)\n",
        "\n",
        "\n",
        "df['label_name'] = df['label'].apply(label_int2str)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Pvo7NwndeoZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['label_name'].value_counts().plot.barh()\n",
        "plt.title('Frequency of classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZvibIIhDkrqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How long are our tweets"
      ],
      "metadata": {
        "id": "BKu-CyCTfsDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Words Per Tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot('Words Per Tweet', by = 'label_name', grid = False, showfliers = False, color = 'black')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8HtcdKiUgCEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "U1SPuQikg7td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From text to tokens"
      ],
      "metadata": {
        "id": "nMPNCExbhVIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Character Tokenization"
      ],
      "metadata": {
        "id": "7ViAkpWXhsQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Tokenizing text is a core task of NLP.'\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "PGXIwAmmhzD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
        "print(token2idx)"
      ],
      "metadata": {
        "id": "JQmYUpKexfBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPIUMgPRzcKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YCju7qWKxfDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SC48iIKUxfGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmqt9A4xxfHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
        "print(token2idx)"
      ],
      "metadata": {
        "id": "aurArBl2h3kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [token2idx[token] for token in tokenized_text]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "dcpBMJ9_ihkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# input_ids = torch.tensor(input_ids)\n",
        "# one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n",
        "# one_hot_encodings.shape"
      ],
      "metadata": {
        "id": "fmnlco7MYpQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_ids = tf.constant(input_ids)\n",
        "one_hot_encodings = tf.one_hot(input_ids, len(token2idx))\n",
        "print(one_hot_encodings.shape)"
      ],
      "metadata": {
        "id": "2JmqOFD_jCsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[0]}\")\n",
        "print(f\"Tensor index: {input_ids[0]}\")\n",
        "print(f\"One-hot: {one_hot_encodings[0]}\")"
      ],
      "metadata": {
        "id": "lvb7JVXajZ-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word tokenization"
      ],
      "metadata": {
        "id": "x1Cdtfaeo3RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = text.split()\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "3t5U330Oo_KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Subword Tokenization"
      ],
      "metadata": {
        "id": "57nFFNLcpB4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "7yChv1FwpXtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Same but more specific\n",
        "from transformers import DistilBertTokenizer\n",
        "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "-O17049opvlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)"
      ],
      "metadata": {
        "id": "V_EPsBD0rUUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "JUrM5xJKB3Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_string(tokens)"
      ],
      "metadata": {
        "id": "_y-GNGWaB3SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "TFnaqiKfB3VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "vwRF3qWUB3Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_input_names"
      ],
      "metadata": {
        "id": "dCrQpsxhB3aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizing the whole dataset"
      ],
      "metadata": {
        "id": "4Bxq7r33B3cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], padding = True, truncation = True)"
      ],
      "metadata": {
        "id": "PdAtL5cWB3e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize(emotions['train'][:2]))"
      ],
      "metadata": {
        "id": "K-rZet2eEQ2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched = True, batch_size = None)"
      ],
      "metadata": {
        "id": "tVaCTafVEQ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformers as feature extractors"
      ],
      "metadata": {
        "id": "2n1deJZNEQ77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "z1eeJP9SEQ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'this is a test'\n",
        "inputs = tokenizer(text, return_tensors = 'pt')\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "5N4a5KcqF-Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(outputs.last_hidden_state.size())"
      ],
      "metadata": {
        "id": "VBjOKTcLF-EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state.size()"
      ],
      "metadata": {
        "id": "6rsKsVj_F-Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
      ],
      "metadata": {
        "id": "sw0nYAVxF-It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state[:, 0].size()"
      ],
      "metadata": {
        "id": "Vw_UTzadI3yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "    inputs = {k: v.to(device) for k, v in batch.items()\n",
        "                                if k in tokenizer.model_input_names}\n",
        "    with torch.no_grad():\n",
        "        last_hidden_state = model(**inputs).last_hidden_state\n",
        "    return {'hidden_states': last_hidden_state[:, 0].cpu().numpy()}"
      ],
      "metadata": {
        "id": "7mhBVYpFI31s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "8GmDkrJoI339"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched = True)"
      ],
      "metadata": {
        "id": "aaN41rW5K1j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden['train'][0]"
      ],
      "metadata": {
        "id": "OjKB8wJRL4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(emotions_hidden['train']['hidden_states'])\n",
        "X_valid = np.array(emotions_hidden['validation']['hidden_states'])\n",
        "y_train = np.array(emotions_hidden['train']['label'])\n",
        "y_valid = np.array(emotions_hidden['validation']['label'])"
      ],
      "metadata": {
        "id": "D1CU8NRlLUyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the training data"
      ],
      "metadata": {
        "id": "8Ku69X1ELU7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "mapper = UMAP(n_components = 2, metric = 'cosine').fit(X_scaled)\n",
        "\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns = ['X', 'Y'])\n",
        "df_emb['label'] = y_train\n",
        "df_emb.head()"
      ],
      "metadata": {
        "id": "K0M6n6UlNxuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize = (7, 5))\n",
        "ax = ax.flatten()\n",
        "cmaps = ['Greys', 'Blues', 'Oranges', 'Reds', 'Purples', 'Greens']\n",
        "labels = emotions['train'].features['label']\n",
        "for i, (label, cmap) in enumerate(zip(labels.names, cmaps)):\n",
        "    df_emb_sub = df_emb.query(f'label == {i}')\n",
        "    ax[i].hexbin(df_emb_sub['X'], df_emb_sub['Y'], cmap = cmap,\n",
        "                 gridsize = 20, linewidths = (0,))\n",
        "    ax[i].set_title(label)\n",
        "    ax[i].set_xticks([]), ax[i].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "khehIqG5O_-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a simple classifier"
      ],
      "metadata": {
        "id": "xOHcwPcENxxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter = 3000)\n",
        "lr_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "G-AyCf35Nxza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "KbJAYj2ENx10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy = 'most_frequent')\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "153q1RdtSVI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "    cm = confusion_matrix(y_true, y_preds, normalize = 'true')\n",
        "    fig, ax = plt.subplots(figsize = (6, 6))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = labels)\n",
        "    disp.plot(cmap = 'Blues', values_format = '.2f', ax = ax, colorbar = False)\n",
        "    plt.title('Normalized confusion matrix')\n",
        "    plt.show()\n",
        "\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels.names)"
      ],
      "metadata": {
        "id": "dQefbtHfSVNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning Transformers"
      ],
      "metadata": {
        "id": "qwkh6geySVQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "num_labels = 6\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
        "                                                           num_labels = num_labels).to(device)"
      ],
      "metadata": {
        "id": "knhxtfCcU6db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average = 'weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'f1': f1}"
      ],
      "metadata": {
        "id": "n94eaNSmU64v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "dJv2WZXSU67_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded['train']) // batch_size\n",
        "model_name = f'{model_ckpt}-finetuned-emotion'\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_name,\n",
        "    num_train_epochs = 2,\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    weight_decay = 0.01,\n",
        "    eval_strategy = 'epoch',\n",
        "    disable_tqdm = False,\n",
        "    logging_steps = logging_steps,\n",
        "    push_to_hub = True\n",
        ")"
      ],
      "metadata": {
        "id": "agUkH4GtU6-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset = emotions_encoded['train'],\n",
        "    eval_dataset = emotions_encoded['validation'],\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "HGqq614TU7As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(emotions_encoded['validation'])"
      ],
      "metadata": {
        "id": "x_XXmO-qU7C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output.metrics"
      ],
      "metadata": {
        "id": "mqtXjp8-fmM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis = 1)"
      ],
      "metadata": {
        "id": "9xzJ3w3kfmP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_preds, y_valid, labels.names)"
      ],
      "metadata": {
        "id": "qnA2iIM0fmSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tuning with Keras"
      ],
      "metadata": {
        "id": "WfYbftTFKmKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "tf_model = (TFAutoModelForSequenceClassification\n",
        "            .from_pretrained(model_ckpt, num_labels=num_labels))"
      ],
      "metadata": {
        "id": "mFSv6NVPLUUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_columns = tokenizer.model_input_names\n",
        "\n",
        "tf_train_dataset = emotions_encoded[\"train\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns, label_cols=[\"label\"], shuffle=True,\n",
        "    batch_size=batch_size)\n",
        "tf_eval_dataset = emotions_encoded[\"validation\"].to_tf_dataset(\n",
        "    columns=tokenizer_columns, label_cols=[\"label\"], shuffle=False,\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "J01xnBIPLXt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "tf_model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=2)"
      ],
      "metadata": {
        "id": "OGzWjpECLaHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Error analysis"
      ],
      "metadata": {
        "id": "mNBwHjJZLiBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_labels(batch):\n",
        "    inputs = {k:v.to(device) for k, v in batch.items()\n",
        "                    if k in tokenizer.model_input_names}\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        pred_label = torch.argmax(output.logits, axis = -1)\n",
        "        loss = cross_entropy(output.logits, batch['label'].to(device),\n",
        "                             reduction = 'none')\n",
        "\n",
        "    return {'loss': loss.cpu().numpy(),\n",
        "            'predicted_label': pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "-CPjq6bCjiAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('torch',\n",
        "                columns = ['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "emotions_encoded['validation'] = emotions_encoded['validation'].map(\n",
        "    forward_pass_with_labels, batched = True, batch_size = 16\n",
        ")"
      ],
      "metadata": {
        "id": "8RWGKsgBjhzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('pandas')\n",
        "cols = ['text', 'label', 'predicted_label', 'loss']\n",
        "df_test = emotions_encoded['validation'][:][cols]\n",
        "df_test['label'] = df_test['label'].apply(label_int2str)\n",
        "df_test['predicted_label'] = df_test['predicted_label'].apply(label_int2str)"
      ],
      "metadata": {
        "id": "UAN977yIjhs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values('loss', ascending= True).iloc[1]['text']"
      ],
      "metadata": {
        "id": "9DiU3xRyn31-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values('loss', ascending= True).head(10)"
      ],
      "metadata": {
        "id": "_EYl9En6jhmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving and Sharing model"
      ],
      "metadata": {
        "id": "Ly36wUtRZoQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message='Training completed!')"
      ],
      "metadata": {
        "id": "ej-bQ3g6ZoTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_id = 'Rustam39/distilbert-base-uncased-finetuned-emotion'\n",
        "classifier = pipeline('text-classification', model = model_id)"
      ],
      "metadata": {
        "id": "0yc4klv_o0r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = 'i was really scared'\n",
        "preds = classifier(tweet, top_k = 6)\n",
        "preds"
      ],
      "metadata": {
        "id": "3TLkh5wno0vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df = pd.DataFrame(preds)\n",
        "preds_df_sorted = preds_df.sort_values('label', ascending = True)\n",
        "plt.bar(labels.names, 100 * preds_df_sorted['score'])\n",
        "plt.title(f'\"{tweet}\"')\n",
        "plt.ylabel('Prediction probability (%)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L5bh7j-Ko0yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNyZuWiFV0wK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}